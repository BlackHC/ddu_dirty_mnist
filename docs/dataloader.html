---

title: DirtyMNIST DataLoader


keywords: fastai
sidebar: home_sidebar

summary: "Ready to go"
description: "Ready to go"
nb_path: "01_dataloader.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 01_dataloader.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We create a new PyTorch <code>VisionDataset</code> for Ambiguous-MNIST and then concatencate it with MNIST (using FastMNIST, <a href="https://tinyurl.com/pytorch-fast-mnist">https://tinyurl.com/pytorch-fast-mnist</a>) to build DirtyMNIST.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="AmbiguousMNIST" class="doc_header"><code>class</code> <code>AmbiguousMNIST</code><a href="https://github.com/BlackHC/ddu_dirty_mnist/tree/master/ddu_dirty_mnist/dirty_mnist.py#L23" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>AmbiguousMNIST</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwds</code></strong>) :: <code>VisionDataset</code></p>
</blockquote>

<pre><code>Ambiguous-MNIST Dataset

Please cite:

    @article{mukhoti2021deterministic,
      title={Deterministic Neural Networks with Appropriate Inductive Biases Capture Epistemic and Aleatoric Uncertainty},
      author={Mukhoti, Jishnu and Kirsch, Andreas and van Amersfoort, Joost and Torr, Philip HS and Gal, Yarin},
      journal={arXiv preprint arXiv:2102.11582},
      year={2021}
    }


Args:
    root (string): Root directory of dataset where ``MNIST/processed/training.pt``
        and  ``MNIST/processed/test.pt`` exist.
    train (bool, optional): If True, creates dataset from ``training.pt``,
        otherwise from ``test.pt``.
    download (bool, optional): If true, downloads the dataset from the internet and
        puts it in root directory. If dataset is already downloaded, it is not
        downloaded again.
    transform (callable, optional): A function/transform that  takes in an PIL image
        and returns a transformed version. E.g, ``transforms.RandomCrop``
    target_transform (callable, optional): A function/transform that takes in the
        target and transforms it.
    normalize (bool, optional): Whiten the samples.
    device: Device to use (pass `num_workers=0, pin_memory=False` to the DataLoader for max throughput)</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="FastMNIST" class="doc_header"><code>class</code> <code>FastMNIST</code><a href="https://github.com/BlackHC/ddu_dirty_mnist/tree/master/ddu_dirty_mnist/dirty_mnist.py#L151" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>FastMNIST</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwds</code></strong>) :: <code>MNIST</code></p>
</blockquote>

<pre><code>FastMNIST, like MNIST (&lt;http://yann.lecun.com/exdb/mnist/&gt;) but faster throughput.

Args:
    root (string): Root directory of dataset where ``MNIST/processed/training.pt``
        and  ``MNIST/processed/test.pt`` exist.
    train (bool, optional): If True, creates dataset from ``training.pt``,
        otherwise from ``test.pt``.
    download (bool, optional): If true, downloads the dataset from the internet and
        puts it in root directory. If dataset is already downloaded, it is not
        downloaded again.
    transform (callable, optional): A function/transform that  takes in an PIL image
        and returns a transformed version. E.g, ``transforms.RandomCrop``
    target_transform (callable, optional): A function/transform that takes in the
        target and transforms it.
    normalize (bool, optional): Whiten the samples.
    device: Device to use (pass `num_workers=0, pin_memory=False` to the DataLoader for
        max throughput).</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="DirtyMNIST" class="doc_header"><code>DirtyMNIST</code><a href="https://github.com/BlackHC/ddu_dirty_mnist/tree/master/ddu_dirty_mnist/dirty_mnist.py#L205" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>DirtyMNIST</code>(<strong><code>root</code></strong>:<code>str</code>, <strong><code>train</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>transform</code></strong>:<code>Optional</code>[<code>Callable</code>]=<em><code>None</code></em>, <strong><code>target_transform</code></strong>:<code>Optional</code>[<code>Callable</code>]=<em><code>None</code></em>, <strong><code>download</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>normalize</code></strong>=<em><code>True</code></em>, <strong><code>device</code></strong>=<em><code>None</code></em>)</p>
</blockquote>

<pre><code>DirtyMNIST

Please cite:

    @article{mukhoti2021deterministic,
      title={Deterministic Neural Networks with Appropriate Inductive Biases Capture Epistemic and Aleatoric Uncertainty},
      author={Mukhoti, Jishnu and Kirsch, Andreas and van Amersfoort, Joost and Torr, Philip HS and Gal, Yarin},
      journal={arXiv preprint arXiv:2102.11582},
      year={2021}
    }

Args:
    root (string): Root directory of dataset where ``MNIST/processed/training.pt``
        and  ``MNIST/processed/test.pt`` exist.
    train (bool, optional): If True, creates dataset from ``training.pt``,
        otherwise from ``test.pt``.
    download (bool, optional): If true, downloads the dataset from the internet and
        puts it in root directory. If dataset is already downloaded, it is not
        downloaded again.
    transform (callable, optional): A function/transform that  takes in an PIL image
        and returns a transformed version. E.g, ``transforms.RandomCrop``
    target_transform (callable, optional): A function/transform that takes in the
        target and transforms it.
    normalize (bool, optional): Whiten the samples.
    device: Device to use (pass `num_workers=0, pin_memory=False` to the DataLoader for
        max throughput).</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Example">Example<a class="anchor-link" href="#Example"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's look at the dataset:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dirty_mnist_train</span> <span class="o">=</span> <span class="n">DirtyMNIST</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This initializes DirtyMNIST and also normalizes the dataset (equivalent to <code>MNIST_NORMALIZATION = Normalize((0.1307,), (0.3081,))</code>) by default---but faster. Use <code>normalize=False</code> if you don't want to normalize the dataset.
{% include tip.html content='We can speed up the dataloader considerably by using <code>normalize=True</code> (default) and <code>num_workers=0, pin_memory=False</code> to the dataloader and use the device parameter to set the target device.' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dirty_mnist_train</span> <span class="o">=</span> <span class="n">DirtyMNIST</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="n">dirty_mnist_dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">dirty_mnist_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dirty_mnist_dataloader</span><span class="p">):</span>
    <span class="n">image</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
    <span class="n">label</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This achieves about 700it/s on a workstation compared to the default MNIST dataset which only achieves 34it/s. This insight is from Joost's <a href="https://tinyurl.com/pytorch-fast-mnist">https://tinyurl.com/pytorch-fast-mnist</a>.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mnist_train</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">Compose</span><span class="p">([</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">MNIST_NORMALIZATION</span><span class="p">]))</span>

<span class="n">mnist_dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">mnist_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="k">for</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">mnist_dataloader</span><span class="p">):</span>
    <span class="k">pass</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

