{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dirty_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DirtyMNIST DataLoader\n",
    "\n",
    "> Ready to go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new PyTorch `VisionDataset` for Ambiguous-MNIST and then concatencate it with MNIST (using FastMNIST, https://tinyurl.com/pytorch-fast-mnist) to build DirtyMNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import os\n",
    "from typing import IO, Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "from urllib.error import URLError\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets.mnist import MNIST, VisionDataset\n",
    "from torchvision.datasets.utils import download_url, extract_archive, verify_str_arg\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "# based on torchvision.datasets.mnist.py (https://github.com/pytorch/vision/blob/37eb37a836fbc2c26197dfaf76d2a3f4f39f15df/torchvision/datasets/mnist.py)\n",
    "\n",
    "MNIST_NORMALIZATION = Normalize((0.1307,), (0.3081,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class AmbiguousMNIST(VisionDataset):\n",
    "    \"\"\"\n",
    "    Ambiguous-MNIST Dataset\n",
    "\n",
    "    Please cite:\n",
    "\n",
    "        @article{mukhoti2021deterministic,\n",
    "          title={Deterministic Neural Networks with Appropriate Inductive Biases Capture Epistemic and Aleatoric Uncertainty},\n",
    "          author={Mukhoti, Jishnu and Kirsch, Andreas and van Amersfoort, Joost and Torr, Philip HS and Gal, Yarin},\n",
    "          journal={arXiv preprint arXiv:2102.11582},\n",
    "          year={2021}\n",
    "        }\n",
    "\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where ``MNIST/processed/training.pt``\n",
    "            and  ``MNIST/processed/test.pt`` exist.\n",
    "        train (bool, optional): If True, creates dataset from ``training.pt``,\n",
    "            otherwise from ``test.pt``.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        normalize (bool, optional): Whiten the samples.\n",
    "        device: Device to use (pass `num_workers=0, pin_memory=False` to the DataLoader for max throughput)\n",
    "    \"\"\"\n",
    "\n",
    "    mirrors = [\"http://github.com/BlackHC/ddu_dirty_mnist/releases/download/data-v0.5.0/\"]\n",
    "\n",
    "    resources = dict(data=(\"amnist_samples.pt\", None), targets=(\"amnist_labels.pt\", None))\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        train: bool = True,\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "        download: bool = False,\n",
    "        normalize: bool = True,\n",
    "        device=None,\n",
    "    ):\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        self.data = torch.load(self.resource_path(\"data\"), map_location=device)\n",
    "        if normalize:\n",
    "            self.data = self.data.sub_(0.1307).div_(0.3081)\n",
    "\n",
    "        self.targets = torch.load(self.resource_path(\"targets\"), map_location=device)\n",
    "\n",
    "        num_multi_labels = self.targets.shape[1]\n",
    "\n",
    "        self.data = self.data.expand(-1, num_multi_labels, 28, 28).reshape(-1, 1, 28, 28)\n",
    "        self.targets = self.targets.reshape(-1)\n",
    "\n",
    "        data_range = slice(None, 60000) if self.train else slice(60000, None)\n",
    "        self.data = self.data[data_range]\n",
    "        self.targets = self.targets[data_range]\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    @property\n",
    "    def data_folder(self) -> str:\n",
    "        return os.path.join(self.root, self.__class__.__name__)\n",
    "\n",
    "    def resource_path(self, name):\n",
    "        return os.path.join(self.data_folder, self.resources[name][0])\n",
    "\n",
    "    def _check_exists(self) -> bool:\n",
    "        return all(os.path.exists(self.resource_path(name)) for name in self.resources)\n",
    "\n",
    "    def download(self) -> None:\n",
    "        \"\"\"Download the data if it doesn't exist in data_folder already.\"\"\"\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        os.makedirs(self.data_folder, exist_ok=True)\n",
    "\n",
    "        # download files\n",
    "        for filename, md5 in self.resources.values():\n",
    "            for mirror in self.mirrors:\n",
    "                url = \"{}{}\".format(mirror, filename)\n",
    "                try:\n",
    "                    print(\"Downloading {}\".format(url))\n",
    "                    download_url(url, root=self.data_folder, filename=filename, md5=md5)\n",
    "                except URLError as error:\n",
    "                    print(\"Failed to download (trying next):\\n{}\".format(error))\n",
    "                    continue\n",
    "                except:\n",
    "                    raise\n",
    "                finally:\n",
    "                    print()\n",
    "                break\n",
    "            else:\n",
    "                raise RuntimeError(\"Error downloading {}\".format(filename))\n",
    "\n",
    "        print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "# based on https://tinyurl.com/pytorch-fast-mnist\n",
    "class FastMNIST(MNIST):\n",
    "    \"\"\"\n",
    "    FastMNIST, like MNIST (<http://yann.lecun.com/exdb/mnist/>) but faster throughput.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where ``MNIST/processed/training.pt``\n",
    "            and  ``MNIST/processed/test.pt`` exist.\n",
    "        train (bool, optional): If True, creates dataset from ``training.pt``,\n",
    "            otherwise from ``test.pt``.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        normalize (bool, optional): Whiten the samples.\n",
    "        device: Device to use (pass `num_workers=0, pin_memory=False` to the DataLoader for\n",
    "            max throughput).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, normalize, device, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # Scale data to [0,1]\n",
    "        self.data = self.data.unsqueeze(1).float().div(255)\n",
    "\n",
    "        # Put both data and targets on GPU in advance\n",
    "        self.data, self.targets = self.data.to(device), self.targets.to(device)\n",
    "\n",
    "        if normalize:\n",
    "            self.data = self.data.sub_(0.1307).div_(0.3081)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def DirtyMNIST(\n",
    "    root: str,\n",
    "    train: bool = True,\n",
    "    transform: Optional[Callable] = None,\n",
    "    target_transform: Optional[Callable] = None,\n",
    "    download: bool = False,\n",
    "    normalize=True,\n",
    "    device=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    DirtyMNIST\n",
    "\n",
    "    Please cite:\n",
    "\n",
    "        @article{mukhoti2021deterministic,\n",
    "          title={Deterministic Neural Networks with Appropriate Inductive Biases Capture Epistemic and Aleatoric Uncertainty},\n",
    "          author={Mukhoti, Jishnu and Kirsch, Andreas and van Amersfoort, Joost and Torr, Philip HS and Gal, Yarin},\n",
    "          journal={arXiv preprint arXiv:2102.11582},\n",
    "          year={2021}\n",
    "        }\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where ``MNIST/processed/training.pt``\n",
    "            and  ``MNIST/processed/test.pt`` exist.\n",
    "        train (bool, optional): If True, creates dataset from ``training.pt``,\n",
    "            otherwise from ``test.pt``.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        normalize (bool, optional): Whiten the samples.\n",
    "        device: Device to use (pass `num_workers=0, pin_memory=False` to the DataLoader for\n",
    "            max throughput).\n",
    "    \"\"\"\n",
    "\n",
    "    mnist_dataset = FastMNIST(\n",
    "        root=root,\n",
    "        train=train,\n",
    "        transform=transform,\n",
    "        target_transform=target_transform,\n",
    "        download=download,\n",
    "        normalize=normalize,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    amnist_dataset = AmbiguousMNIST(\n",
    "        root=root,\n",
    "        train=train,\n",
    "        transform=transform,\n",
    "        target_transform=target_transform,\n",
    "        download=download,\n",
    "        normalize=normalize,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    return torch.utils.data.ConcatDataset([mnist_dataset, amnist_dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_mnist_train = DirtyMNIST(\".\", train=True, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This initializes DirtyMNIST and also normalizes the dataset (equivalent to `MNIST_NORMALIZATION = Normalize((0.1307,), (0.3081,))`) by default---but faster. Use `normalize=False` if you don't want to normalize the dataset.\n",
    "\n",
    "> Tip: We can speed up the dataloader considerably by using `normalize=True` (default) and `num_workers=0, pin_memory=False` to the dataloader and use the device parameter to set the target device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6299c4069dd54457bac938901e4df907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gpu\n",
    "\n",
    "dirty_mnist_train = DirtyMNIST(\".\", train=True, download=True, device=\"cuda\")\n",
    "\n",
    "dirty_mnist_dataloader = torch.utils.data.DataLoader(\n",
    "    dirty_mnist_train, batch_size=128, shuffle=True, num_workers=0, pin_memory=False\n",
    ")\n",
    "\n",
    "for image, label in tqdm(dirty_mnist_dataloader):\n",
    "    image.cuda()\n",
    "    label.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This achieves about 700it/s on a workstation compared to the default MNIST dataset which only achieves 34it/s. This insight is from Joost's https://tinyurl.com/pytorch-fast-mnist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552ff165429a403abbab55ae65ab6fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_train = MNIST(\".\", train=True, download=True, transform=Compose([ToTensor(), MNIST_NORMALIZATION]))\n",
    "\n",
    "mnist_dataloader = torch.utils.data.DataLoader(\n",
    "    mnist_train, batch_size=128, shuffle=True, num_workers=0, pin_memory=True\n",
    ")\n",
    "for image, label in tqdm(mnist_dataloader):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ddu_dirty_mnist]",
   "language": "python",
   "name": "conda-env-ddu_dirty_mnist-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
