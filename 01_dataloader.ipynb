{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dirty_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DirtyMNIST DataLoader\n",
    "\n",
    "> Ready to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "import os\n",
    "from typing import IO, Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "from urllib.error import URLError\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets.mnist import MNIST, VisionDataset\n",
    "from torchvision.datasets.utils import (\n",
    "    download_and_extract_archive,\n",
    "    download_url,\n",
    "    extract_archive,\n",
    "    verify_str_arg,\n",
    ")\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "# based on torchvision.datasets.mnist.py (https://github.com/pytorch/vision/blob/37eb37a836fbc2c26197dfaf76d2a3f4f39f15df/torchvision/datasets/mnist.py)\n",
    "\n",
    "MNIST_NORMALIZATION = Normalize((0.1307,), (0.3081,))\n",
    "\n",
    "\n",
    "class AmbiguousMNIST(VisionDataset):\n",
    "    mirrors = [\"http://github.com/BlackHC/ddu_dirty_mnist/releases/download/data-v0.5.0/\"]\n",
    "\n",
    "    resources = dict(data=(\"amnist_labels.pt\", None), targets=(\"amnist_samples.pt\", None))\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        train: bool = True,\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "        download: bool = False,\n",
    "        device=None,\n",
    "    ):\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        data_range = slice(None, 60000) if self.train else slice(60000, None)\n",
    "\n",
    "        self.data = torch.load(self.resource_path(\"data\"), map_location=device)[data_range]\n",
    "        self.targets = torch.load(self.resource_path(\"targets\"), map_location=\"cpu\")[data_range]\n",
    "\n",
    "        num_multi_labels = self.targets.shape[1]\n",
    "        self.data = self.data.expand(-1, num_multi_labels, 28, 28).reshape(-1, 1, 28, 28)\n",
    "        self.targets = self.targets.reshape(-1)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index].unsqueeze, int(self.targets[index])\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    @property\n",
    "    def data_folder(self) -> str:\n",
    "        return os.path.join(self.root, self.__class__.__name__)\n",
    "\n",
    "    def resource_path(self, name):\n",
    "        print(name)\n",
    "        return os.path.join(self.data_folder, self.resources[name][0])\n",
    "\n",
    "    def _check_exists(self) -> bool:\n",
    "        return all(os.path.exists(self.resource_path(name)) for name in self.resources)\n",
    "\n",
    "    def download(self) -> None:\n",
    "        \"\"\"Download the data if it doesn't exist in data_folder already.\"\"\"\n",
    "\n",
    "        print(0)\n",
    "        if self._check_exists():\n",
    "            return\n",
    "        print(0)\n",
    "\n",
    "        os.makedirs(self.data_folder, exist_ok=True)\n",
    "\n",
    "        # download files\n",
    "        for filename, md5 in self.resources.values():\n",
    "            for mirror in self.mirrors:\n",
    "                url = \"{}{}\".format(mirror, filename)\n",
    "                try:\n",
    "                    print(\"Downloading {}\".format(url))\n",
    "                    download_and_extract_archive(url, download_root=self.data_folder, filename=filename, md5=md5)\n",
    "                except URLError as error:\n",
    "                    print(\"Failed to download (trying next):\\n{}\".format(error))\n",
    "                    continue\n",
    "                except:\n",
    "                    raise\n",
    "                finally:\n",
    "                    print()\n",
    "                break\n",
    "            else:\n",
    "                raise RuntimeError(\"Error downloading {}\".format(filename))\n",
    "\n",
    "        print(\"Done!\")\n",
    "\n",
    "\n",
    "def DirtyMNIST(\n",
    "    root: str,\n",
    "    train: bool = True,\n",
    "    transform: Optional[Callable] = None,\n",
    "    target_transform: Optional[Callable] = None,\n",
    "    download: bool = False,\n",
    "):\n",
    "    mnist_transform = Compose([ToTensor(), transform]) if transform else ToTensor()\n",
    "    mnist_dataset = MNIST(\n",
    "        root=root, train=train, transform=mnist_transform, target_transform=target_transform, download=download\n",
    "    )\n",
    "    amnist_dataset = AmbiguousMNIST(\n",
    "        root=root, train=train, transform=transform, target_transform=target_transform, download=download\n",
    "    )\n",
    "\n",
    "    return torch.utils.data.ConcatDataset(mnist_dataset, amnist_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "data\n",
      "0\n",
      "Downloading http://github.com/BlackHC/ddu_dirty_mnist/releases/download/data-v0.5.0/amnist_labels.pt\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error downloading amnist_labels.pt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-489829e6439e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdirty_mnist_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDirtyMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMNIST_NORMALIZATION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-4b7093725307>\u001b[0m in \u001b[0;36mDirtyMNIST\u001b[0;34m(root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmnist_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 125\u001b[0;31m     amnist_dataset = AmbiguousMNIST(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-41-4b7093725307>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download, device)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mdata_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-4b7093725307>\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error downloading {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error downloading amnist_labels.pt"
     ]
    }
   ],
   "source": [
    "dirty_mnist_train = DirtyMNIST(\".\", train=True, download=True, transform=MNIST_NORMALIZATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ddu_dirty_mnist]",
   "language": "python",
   "name": "conda-env-ddu_dirty_mnist-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
